---
title: '<center> <h1>Logistic regression model in R using TensorFlow</h1></center>'
author: '<center> <h3>Vadim I. Nazarov</h3> </center> <center> <h4><vdm.nazarov@gmail.com></h4> </center>'
output: 
  html_document: 
    theme: spacelab
---

#### Preface
This is an R version of the wonderful TensorFlow example made by [Aymeric Damien](https://github.com/aymericdamien) in [this project](https://github.com/aymericdamien/TensorFlow-Examples/).

Original TensorFlow example notebook: [link](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/2_BasicModels/logistic_regression.ipynb)

Code for this document: [link](https://github.com/vadimnazarov/tensorflow-r-examples/src/2_BasicModels/logistic_regression.Rmd)

TensorFlow R examples website: [link](https://vadimnazarov.github.io/tensorflow-r-examples/)

TensorFlow R examples GitHub: [link](https://github.com/vadimnazarov/tensorflow-r-examples/)

#### Installation
Installation instructions for TensorFlow R package: [link](https://rstudio.github.io/tensorflow/)

#### Libraries
```{r libs}
library(tensorflow)
```

#### Parameters
```{r params}
learning_rate = 0.1
training_epochs = 25
batch_size = 100
test_size = 3000
n_features = 784L
n_classes = 10L
verbose_step = 1
```

#### Training data
```{r data}
input_data = tf$contrib$learn$datasets$mnist
mnist = input_data$read_data_sets("./tmp/data", one_hot = T)
list.files("./tmp/data")
```

#### TensorFlow graph input
```{r input}
x = tf$placeholder(tf$float32, shape(NULL, n_features))
y = tf$placeholder(tf$float32, shape(NULL, n_classes))
```

#### Initial weights for the model
```{r weights}
W = tf$Variable(tf$zeros(shape(n_features, n_classes)))
b = tf$Variable(tf$zeros(shape(n_classes)))
```

#### Logistic model description
```{r model}
lr_model = tf$nn$softmax(tf$matmul(x, W) + b)
```

#### Loss function - cross entropy
```{r loss}
loss_fun = tf$reduce_mean(-tf$reduce_sum(y * tf$log(lr_model), reduction_indices = 1L))
```

#### Optimisation using the gradient descent algorithm
```{r optim}
optim_fun = tf$train$GradientDescentOptimizer(learning_rate)$minimize(loss_fun)
```

#### Initialise all variables
```{r init}
init = tf$initialize_all_variables()
```

#### Launch the graph and print the resulting accuracy
```{r run}
with(tf$Session() %as% sess, {
  sess$run(init)
  
  # For every epoch
  for (epoch in 1:training_epochs) {
    avg_loss = .0
    total_batch = as.integer(mnist$train$num_examples / batch_size)
    # For every batch
    for (i in 1:total_batch) {
      # Fit a subset of the data
      batch_data = mnist$train$next_batch(total_batch)
      sess$run(optim_fun, feed_dict = dict(x = batch_data[[1]], y = batch_data[[2]]))
      cur_loss = sess$run(loss_fun, feed_dict = dict(x = batch_data[[1]], y = batch_data[[2]]))
      avg_loss = avg_loss + cur_loss / total_batch
    }
    
    if (epoch %% verbose_step == 0) {
      cat(paste0("Epoch: ", format(epoch, width = 2), 
                 " avg.loss=", format(avg_loss, width = 10)), "\n")
    }
  }
  
  training_loss = sess$run(loss_fun, feed_dict = dict(x = mnist$test$images[1:test_size, ], y = mnist$test$labels[1:test_size, ]))
  cat(paste0("Overall loss=", format(training_loss, width = 10)), "\n")

  corr_pred = tf$equal(tf$argmax(lr_model, 1L), tf$argmax(y, 1L))
  acc = tf$reduce_mean(tf$cast(corr_pred, tf$float32))
  cat("Accuracy: ", acc$eval(dict(x = mnist$test$images[1:test_size, ], y = mnist$test$labels[1:test_size, ])), "\n")
})
```